{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Stage 4: Filtering Based on Keyword Scores\n",
    "\n",
    "Welcome to Pipeline 4! In this stage, we will use the scores generated from Pipeline 3 to identify and select the best matches between students and companies. This filtering process ensures that the highest-scoring pairs, indicating the strongest alignment, are prioritized, leading to optimal matches for both students and employers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~\n",
    "import os \n",
    "import re\n",
    "import time \n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# Custom imports\n",
    "from mypackage.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the project path\n",
    "path_to_project = load_project_path()\n",
    "\n",
    "if path_to_project:\n",
    "    print(f\"Project path loaded: {path_to_project}\")\n",
    "else:\n",
    "    print(\"Please set the project path in the initial notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_load_path = f'{path_to_project}/data/SP_table/SP3_post_keyword_scoring.parquet'\n",
    "SP = pd.read_parquet(SP_load_path)\n",
    "print(SP.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is code to calculate the Pearson correlation coefficient between the Total Points and Extraction_total_points columns. I wanted to see if the new scoring logic I implemented has a strong correlation with the original scoring logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Pearson correlation coefficient\n",
    "def calculate_correlation(df):\n",
    "    correlation, p_value = pearsonr(df['Total Points'], df['Extraction_total_points'])\n",
    "    print(f\"Pearson correlation coefficient: {correlation}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "    return correlation\n",
    "\n",
    "# Plot the scatter plot and regression line\n",
    "def plot_regression(df):\n",
    "    # Create scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='Total Points', y='Extraction_total_points', data=df, color='blue', label='Data points')\n",
    "\n",
    "    # Perform linear regression\n",
    "    X = df['Total Points'].values.reshape(-1, 1)\n",
    "    y = df['Extraction_total_points'].values\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    y_pred = reg.predict(X)\n",
    "\n",
    "    # Plot regression line\n",
    "    plt.plot(df['Total Points'], y_pred, color='red', linewidth=2, label='Line of best fit')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Total Points')\n",
    "    plt.ylabel('Extraction_total_points')\n",
    "    plt.title('Scatter Plot with Regression Line')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Regression slope: {reg.coef_[0]}\")\n",
    "    print(f\"Regression intercept: {reg.intercept_}\")\n",
    "\n",
    "# Perform the analysis on the DataFrame\n",
    "def perform_correlation_analysis(df):\n",
    "    # Step 1: Calculate correlation\n",
    "    calculate_correlation(df)\n",
    "    \n",
    "    # Step 2: Plot and perform regression\n",
    "    plot_regression(df)\n",
    "\n",
    "# Assuming your DataFrame is called SP, you would run:\n",
    "perform_correlation_analysis(SP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows a significant but only moderate correlation between the Total Points and Extraction_total_points columns. So a higher match score score based on the current logic does not necessarily mean a higher match score based on the new logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "We will now apply some filtering based on the generated scores. \n",
    "The goal with filtering is to make sure only qualified candidates are matched with job postings. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where Extraction_total_points is 0\n",
    "SP = SP[SP['Extraction_total_points'] > 0]\n",
    "\n",
    "# Be sure to Identify the Job Postings that were entirely deleted\n",
    "# Group by 'pos_(Do Not Modify) Job Posting' and find those that have no remaining rows in SP_filtered\n",
    "deleted_postings = SP[~SP['pos_(Do Not Modify) Job Posting'].isin(SP['pos_(Do Not Modify) Job Posting'])]\n",
    "\n",
    "print(\"Number of deleted job postings:\")\n",
    "print(len(deleted_postings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the Matching Strategy\n",
    "\n",
    "This code implements an iterative matching strategy designed to ensure that each student is matched with no more than 5 companies, while prioritizing the highest alignment scores (`Extraction_total_points`) between students and companies.\n",
    "\n",
    "#### Key Steps in the Matching Process:\n",
    "\n",
    "1. **Initial Sorting:**\n",
    "   - The DataFrame `SP` is sorted by `pos_(Do Not Modify) Job Posting` and `Extraction_total_points` in descending order. This ensures that for each company, the top matches (with the highest alignment scores) are prioritized.\n",
    "\n",
    "2. **Iterative Matching Rounds:**\n",
    "   - The matching process is conducted in multiple rounds. In each round, the top match for each company is selected from the remaining pool of students.\n",
    "\n",
    "3. **Processing Top Matches:**\n",
    "   - For each company in a given round, the top match (the student with the highest alignment score for that company) is identified and collected.\n",
    "\n",
    "4. **Tracking Student Matches:**\n",
    "   - The code maintains a dictionary (`student_matches`) that tracks all the matches for each student across all rounds.\n",
    "   - After collecting new matches for the current round, the code ensures that each student retains only their top 5 matches based on `Extraction_total_points`.\n",
    "\n",
    "5. **Updating Final Matches:**\n",
    "   - The selected matches (limited to the top 5 for each student) are added to the `final_matches` DataFrame, which accumulates all the valid matches throughout the process.\n",
    "\n",
    "6. **Removing Fully Matched Students:**\n",
    "   - Students who have reached their maximum of 5 matches are removed from the pool (`SP_sorted`). This ensures they are not considered in subsequent rounds, preventing over-matching.\n",
    "\n",
    "7. **Loop Termination:**\n",
    "   - The loop continues until no students are left in the pool (`SP_sorted.empty`), meaning all students have either reached their maximum matches or no suitable matches remain.\n",
    "\n",
    "8. **Counting Rounds:**\n",
    "   - The variable `num_rounds` tracks the number of iterations (rounds) needed to complete the matching process.\n",
    "\n",
    "#### Output:\n",
    "- The final output is a DataFrame `final_matches` that contains all the matches, limited to the top 5 matches per student, ensuring an optimal distribution based on alignment scores.\n",
    "- Additionally, the number of rounds taken to complete the matching process is printed, providing insight into the efficiency of the matching strategy.\n",
    "\n",
    "### Key Characteristics of the Strategy:\n",
    "- **Prioritization of Top Matches:** The strategy consistently prioritizes the highest alignment scores for each company, ensuring that the best possible matches are made.\n",
    "- **Controlled Match Distribution:** By limiting each student to a maximum of 5 matches, the strategy prevents any student from being over-matched, ensuring a fair distribution across all companies.\n",
    "- **Iterative Approach:** The iterative nature of the strategy allows for flexibility, as it continuously re-evaluates and refines the matches until an optimal solution is reached.\n",
    "\n",
    "This approach is efficient and ensures that the most aligned matches are prioritized while adhering to the constraint that no student is matched with more than 5 companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 0\n",
    "# Step 1: Sort the DataFrame by company and alignment score\n",
    "SP_sorted = SP.sort_values(by=['pos_(Do Not Modify) Job Posting', 'Extraction_total_points'], ascending=[True, False])\n",
    "\n",
    "# Initialize an empty DataFrame to store the final matches\n",
    "final_matches = pd.DataFrame(columns=SP.columns)\n",
    "\n",
    "# Initialize a dictionary to keep track of all student matches (not just counts)\n",
    "student_matches = defaultdict(list)\n",
    "\n",
    "# Set the maximum number of matches each company and student should get\n",
    "max_matches_per_student = 5\n",
    "\n",
    "# Iterative matching process\n",
    "while not SP_sorted.empty:\n",
    "    # Get the top match for each company\n",
    "    top_matches = SP_sorted.groupby('pos_(Do Not Modify) Job Posting').head(1)\n",
    "\n",
    "    # Initialize a list to collect matches for this round\n",
    "    round_matches = []\n",
    "\n",
    "    # Process each top match\n",
    "    for index, row in top_matches.iterrows():\n",
    "        student = row['stu_(Do Not Modify) Application']\n",
    "        company = row['pos_(Do Not Modify) Job Posting']\n",
    "\n",
    "        # Collect matches for each student\n",
    "        round_matches.append(row)\n",
    "    \n",
    "    # Convert round_matches to DataFrame\n",
    "    round_matches_df = pd.DataFrame(round_matches)\n",
    "\n",
    "    # Update the student_matches dictionary with new matches\n",
    "    for student in round_matches_df['stu_(Do Not Modify) Application'].unique():\n",
    "        # Append new matches for this student\n",
    "        student_matches[student].extend(round_matches_df[round_matches_df['stu_(Do Not Modify) Application'] == student].to_dict('records'))\n",
    "        \n",
    "        # Keep only the top 5 matches for the student\n",
    "        student_matches[student] = sorted(student_matches[student], key=lambda x: x['Extraction_total_points'], reverse=True)[:max_matches_per_student]\n",
    "\n",
    "    # Create a DataFrame from the selected matches to add to final_matches\n",
    "    selected_matches = pd.DataFrame([match for matches in student_matches.values() for match in matches])\n",
    "    \n",
    "    if num_rounds == 0:\n",
    "        final_matches = selected_matches.copy()\n",
    "    else:\n",
    "        final_matches = pd.concat([final_matches, selected_matches]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Remove students who have reached their maximum matches from SP_sorted\n",
    "    fully_matched_students = [student for student, matches in student_matches.items() if len(matches) >= max_matches_per_student]\n",
    "    SP_sorted = SP_sorted[~SP_sorted['stu_(Do Not Modify) Application'].isin(fully_matched_students)]\n",
    "    \n",
    "    num_rounds += 1\n",
    "    # Stop if there are no more students to match\n",
    "\n",
    "# final_matches now contains the distributed matches limited to the top 5 for each student\n",
    "print(f\"Number of rounds: {num_rounds}\")\n",
    "print(f\"Number of final matches: {final_matches.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "We now have a dataframe containing the filtered matches. I will print the number of matches each company and student received.\n",
    "'''\n",
    "\n",
    "pos_cols = ''' \n",
    "pos_Name\n",
    "pos_Company\n",
    "pos_(Do Not Modify) Job Posting\n",
    "'''\n",
    "pos_cols = as_list(pos_cols)\n",
    "\n",
    "company_match_counts = final_matches[pos_cols].copy()\n",
    "\n",
    "# add a column to company_match_counts that counts the number of matches each company received. This is done by counting the number of times 'pos_(Do Not Modify) Job Posting' shows up in the final_matches dataframe.\n",
    "company_match_counts['num_matches'] = company_match_counts.groupby('pos_(Do Not Modify) Job Posting')['pos_(Do Not Modify) Job Posting'].transform('count')\n",
    "\n",
    "# drop duplicates\n",
    "company_match_counts = company_match_counts.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# sort by num_matches\n",
    "company_match_counts = company_match_counts.sort_values(by='num_matches', ascending=False)\n",
    "\n",
    "stu_cols = ''' \n",
    "stu_Legal Name\n",
    "stu_(Do Not Modify) Application\n",
    "'''\n",
    "\n",
    "stu_cols = as_list(stu_cols)\n",
    "\n",
    "student_match_counts = final_matches[stu_cols].copy()\n",
    "\n",
    "# add a column to student_match_counts that counts the number of matches each student received. This is done by counting the number of times 'stu_(Do Not Modify) Application' shows up in the final_matches dataframe.\n",
    "student_match_counts['num_matches'] = student_match_counts.groupby('stu_(Do Not Modify) Application')['stu_(Do Not Modify) Application'].transform('count')\n",
    "\n",
    "# drop duplicates\n",
    "student_match_counts = student_match_counts.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# sort by num_matches\n",
    "student_match_counts = student_match_counts.sort_values(by='num_matches', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(company_match_counts[['pos_Company', 'pos_Name', 'num_matches']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(student_match_counts[['stu_Legal Name', 'num_matches']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results\n",
    "\n",
    "The final results from the matching process yield a more evenly distributed set of matches. Every student is matched with at least one job posting, and each company receives at least four matches. In the next step of the pipeline, we will narrow down these matches to identify the top three candidates for each job posting. Below are some examples of the matches that were generated by this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is a list of Companies from 2024. If you'd like to see the matches for a specific company, copy and paste the name in the 'Company_Name' variable below.\n",
    "\n",
    "company_names = company_match_counts['pos_Company'].unique()\n",
    "for company in company_names:\n",
    "    print(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Company_Name = 'Clothing Brand'\n",
    "\n",
    "cols = ''' \n",
    "pos_Company\n",
    "pos_Name\n",
    "stu_Legal Name\n",
    "Extraction_total_points\n",
    "Tech_total_points_breakup\n",
    "Industry_total_points_breakup\n",
    "Values_total_points_breakup\n",
    "Soft_Skills_total_points_breakup\n",
    "Total Points\n",
    "Total Points BreakUp\n",
    "Tech_total_points\n",
    "pos_technical_keywords\n",
    "stu_technical_keywords\n",
    "Industry_total_points\n",
    "pos_industry_keywords\n",
    "stu_industry_keywords\n",
    "Soft_Skills_total_points\n",
    "pos_soft_keywords\n",
    "stu_soft_keywords\n",
    "Values_total_points\n",
    "pos_values_keywords\n",
    "stu_values_keywords\n",
    "pos_(Do Not Modify) Job Posting\n",
    "stu_(Do Not Modify) Application\n",
    "'''\n",
    "\n",
    "# create a subset of SP with the columns in cols\n",
    "company_match = final_matches[as_list(cols)]\n",
    "company_match = (company_match[company_match['pos_Company'] == Company_Name])\n",
    "\n",
    "# print legacy_health, order by 'Extraction_total_points' in descending order\n",
    "pretty_print(company_match.sort_values(by='Extraction_total_points', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
